{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            age       histology\n",
       " id                             \n",
       " GSM491937  68.0    Endometrioid\n",
       " GSM491938  81.0  Carcinosarcoma\n",
       " GSM491939  56.0                \n",
       " GSM491940  62.0                \n",
       " GSM491941  72.0        Mucinous\n",
       " ...         ...             ...\n",
       " GSM492472  58.0                \n",
       " GSM492473  61.0                \n",
       " GSM492474  72.0                \n",
       " GSM492475  65.0                \n",
       " GSM492476  64.0                \n",
       " \n",
       " [540 rows x 2 columns],\n",
       "             GSM491937  GSM491938  GSM491939  GSM491940  GSM491941  GSM491942  \\\n",
       " id                                                                             \n",
       " cg00000292   0.756367   0.834702   0.774165   0.799517   0.819867   0.802813   \n",
       " cg00002426   0.797859   0.859538   0.769661   0.854328   0.853270   0.863897   \n",
       " cg00003994   0.068605   0.067469   0.056937   0.063802   0.061275   0.054674   \n",
       " cg00005847   0.131004   0.197486   0.140949   0.168209   0.137825   0.183501   \n",
       " cg00006414   0.076355   0.096817   0.156980   0.086761   0.079826   0.068110   \n",
       " ...               ...        ...        ...        ...        ...        ...   \n",
       " cg27657283   0.054350   0.060951   0.054692   0.051071   0.046700   0.058768   \n",
       " cg27661264   0.253198   0.427664   0.210370   0.241700   0.147942   0.335951   \n",
       " cg27662379   0.028654   0.022261   0.027410   0.025137   0.026827   0.027271   \n",
       " cg27662877   0.045494   0.044785   0.044007   0.032319   0.040882   0.041743   \n",
       " cg27665659   0.046754   0.051954   0.046282   0.043402   0.041331   0.040325   \n",
       " \n",
       "             GSM491943  GSM491944  GSM491945  GSM491946  ...  GSM492467  \\\n",
       " id                                                      ...              \n",
       " cg00000292   0.766562   0.822293   0.719792   0.804761  ...   0.807832   \n",
       " cg00002426   0.753301   0.800000   0.729566   0.849711  ...   0.864014   \n",
       " cg00003994   0.069777   0.068445   0.126118   0.067532  ...   0.054327   \n",
       " cg00005847   0.193419   0.136081   0.234453   0.165346  ...   0.150090   \n",
       " cg00006414   0.082719   0.080460   0.123699   0.099133  ...   0.088297   \n",
       " ...               ...        ...        ...        ...  ...        ...   \n",
       " cg27657283   0.088867   0.057243   0.157115   0.073481  ...   0.065930   \n",
       " cg27661264   0.278894   0.287979   0.292254   0.259373  ...   0.303476   \n",
       " cg27662379   0.022631   0.029155   0.027861   0.026356  ...   0.028295   \n",
       " cg27662877   0.045181   0.048036   0.068568   0.040477  ...   0.058025   \n",
       " cg27665659   0.046106   0.050578   0.045932        NaN  ...   0.045390   \n",
       " \n",
       "             GSM492468  GSM492469  GSM492470  GSM492471  GSM492472  GSM492473  \\\n",
       " id                                                                             \n",
       " cg00000292   0.755824   0.845683   0.832651   0.859874   0.850640   0.785949   \n",
       " cg00002426   0.832049   0.869352   0.852637   0.851757   0.811812   0.863659   \n",
       " cg00003994   0.062455   0.061526   0.053024   0.067747   0.046001   0.065620   \n",
       " cg00005847   0.200854   0.222263   0.145972   0.130132   0.165387   0.149490   \n",
       " cg00006414   0.087050   0.075793   0.076368   0.083054   0.074648   0.078410   \n",
       " ...               ...        ...        ...        ...        ...        ...   \n",
       " cg27657283   0.051468   0.044607   0.046881   0.047645   0.060186   0.044991   \n",
       " cg27661264   0.274077   0.364820   0.368968   0.379232   0.371981   0.433100   \n",
       " cg27662379   0.029780   0.030459   0.024485   0.018455   0.030636   0.034338   \n",
       " cg27662877   0.064934   0.047541   0.049245   0.039609   0.045670   0.033494   \n",
       " cg27665659   0.049339   0.044413   0.047632   0.047909   0.048369   0.037386   \n",
       " \n",
       "             GSM492474  GSM492475  GSM492476  \n",
       " id                                           \n",
       " cg00000292   0.827493   0.817919   0.555077  \n",
       " cg00002426   0.815332   0.860943   0.511268  \n",
       " cg00003994   0.055990   0.062512   0.210708  \n",
       " cg00005847   0.155754   0.129134   0.066549  \n",
       " cg00006414   0.091335   0.065681   0.056630  \n",
       " ...               ...        ...        ...  \n",
       " cg27657283   0.056461   0.047952   0.187679  \n",
       " cg27661264   0.422606   0.433005   0.499545  \n",
       " cg27662379   0.035688   0.034179   0.022769  \n",
       " cg27662877   0.035118   0.040766   0.092554  \n",
       " cg27665659   0.043518   0.048207   0.040923  \n",
       " \n",
       " [27578 rows x 540 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from biolearn.data_library import DataLibrary\n",
    "import pandas as pd\n",
    "# https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE19711\n",
    "\n",
    "data = DataLibrary().get(\"GSE19711\").load()\n",
    "data.metadata, data.dnam\n",
    "\n",
    "#elastic for selection, boost for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "X = data.dnam.transpose()\n",
    "X_df = pd.DataFrame(X)\n",
    "y = data.metadata['age']\n",
    "y = pd.DataFrame(y)\n",
    "cb = pd.merge(X_df, y, left_index=True, right_index=True)\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "cb = pd.DataFrame(imputer.fit_transform(cb), columns=cb.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfe for feature selection\n",
    "\n",
    "\n",
    "X_imputed = cb.drop(columns=['age'])\n",
    "y_imputed = cb['age']\n",
    "\n",
    "# Feature selection using RFE with SVM\n",
    "svr = SVR(kernel='linear')\n",
    "rfe = RFE(estimator=svr, n_features_to_select=500, step=1000)\n",
    "rfe.fit(X_imputed, y_imputed)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_imputed.columns[rfe.support_]\n",
    "\n",
    "# Select the top 200 features\n",
    "X_selected = X_imputed[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to DataFrame\n",
    "selected_features_df = pd.DataFrame(X_selected.columns, columns=['Feature'])\n",
    "\n",
    "# Save to CSV\n",
    "selected_features_df.to_csv('X_selected.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.150098223283052, 2.4971224168628603, 0.8291762990253048)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_imputed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an SVM model\n",
    "svm_model = SVR(kernel='linear',C=10, epsilon=1.8)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "evlua = pandas.read_csv('GSE246337_betas.csv')\n",
    "evlua2 = evlua.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = pd.read_csv('X_selected.csv', header=None, names=['feature_name'])\n",
    "\n",
    "# Extract feature names as a list\n",
    "selected_feature_names = selected_features['feature_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = evlua[evlua['Unnamed: 0'].str.startswith(tuple(selected_feature_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "evluafilter2 = filtered_dataset.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "g=np.array(evluafilter2)\n",
    "g2=g[1:]\n",
    "g2\n",
    "g3=pd.DataFrame(g2)\n",
    "g3\n",
    "g3 = pd.DataFrame(imputer.fit_transform(g3), columns=g3.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing_features = set(X_selected.columns) - set(g3.columns)\n",
    "len(set(g3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petra/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 154 features, but SVR is expecting 176 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_new_pred \u001b[38;5;241m=\u001b[39m \u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save predictions to a CSV file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampleId\u001b[39m\u001b[38;5;124m'\u001b[39m: g3\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictedAge\u001b[39m\u001b[38;5;124m'\u001b[39m: y_new_pred})\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/svm/_base.py:429\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    414\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/svm/_base.py:607\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    604\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 607\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    617\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 154 features, but SVR is expecting 176 features as input."
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_new_pred = svm_model.predict(g3)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions = pd.DataFrame({'sampleId': g3.index, 'predictedAge': y_new_pred})\n",
    "predictions.to_csv('predicted_ages.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'predicted_ages.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predicted_ages.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to a CSV file\n",
    "predictions = pd.DataFrame({'sampleId': evlua2.index[1:,], 'predictedAge': y_new_pred})\n",
    "predictions.to_csv('predicted_ages2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Assuming X_genomic is your genomic dataset and y_age is the corresponding age labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the ElasticNetCV model\n",
    "alpha_values = np.logspace(-3, 3, 10)  # Range of alpha values to search\n",
    "l1_ratio_values = [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]  # Range of l1_ratio values to search\n",
    "elasticnet_cv = ElasticNetCV(alphas=alpha_values, l1_ratio=l1_ratio_values, cv=5)\n",
    "elasticnet_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the selected alpha and l1_ratio values\n",
    "print(\"Selected alpha:\", elasticnet_cv.alpha_)\n",
    "print(\"Selected l1_ratio:\", elasticnet_cv.l1_ratio_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_score = elasticnet_cv.score(X_test, y_test)\n",
    "print(\"Test Set R^2 Score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  feature selection\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "X_feat = X\n",
    "y_feat = y\n",
    "# X_feat, y = make_regression(n_samples=100, n_features=100, noise=0.1, random_state=42)\n",
    "model = ElasticNet(alpha=0.00464, l1_ratio=0.1) \n",
    "model.fit(X_feat, y_feat)\n",
    "feature_importance = model.coef_\n",
    "sorted_indices = np.argsort(np.abs(feature_importance))[::-1]\n",
    "top_features = sorted_indices[:10]\n",
    "# print(\"Top features:\")\n",
    "# for idx in top_features:\n",
    "#     print(f\"Feature {idx}: {feature_importance[idx]}\")\n",
    "top_feature_names = X_feat.columns[top_features]\n",
    "top_feature_coefficients = feature_importance[top_features]\n",
    "\n",
    "# Create a DataFrame with feature names and their coefficients\n",
    "feature_data = pd.DataFrame({\n",
    "    'Feature': top_feature_names,\n",
    "    'Coefficient': top_feature_coefficients\n",
    "})\n",
    "\n",
    "print(\"Top features and their coefficients:\")\n",
    "print(feature_data)\n",
    "\n",
    "# Output to CSV\n",
    "feature_data.to_csv('top_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### XGBoost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "#X_choose, y = make_regression(n_samples=100, n_features=100, noise=0.1, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(choose.drop('age', axis=1), choose['age'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=150, learning_rate=0.15, max_depth=2, reg_alpha=1, reg_lambda=0.1)\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric='rmse', early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = xgb_model.score(X_train, y_train)\n",
    "test_score = xgb_model.score(X_test, y_test)\n",
    "print(\"XGBoost model train score:\", train_score)\n",
    "print(\"XGBoost model test score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predictions on the training and testing sets\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE on training set:\", mse_train)\n",
    "print(\"MSE on testing set:\", mse_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "\n",
    "# Calculate R-squared (R2) score\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(\"R-squared (R2) score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],      # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Instantiate the Random Forest regressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_train_pred = best_rf_model.predict(X_train)\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE on training set with best model:\", mse_train)\n",
    "print(\"MSE on testing set with best model:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Instantiate a new Random Forest model with the best parameters\n",
    "best_rf_model = RandomForestRegressor(n_estimators=150,\n",
    "                                       #max_depth=5,\n",
    "                                       min_samples_split=2,\n",
    "                                       min_samples_leaf=4,\n",
    "                                       random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE on testing set with best model:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb[['age', 'cg06493994','cg22736354', 'cg18219226', 'cg02228185',\t'cg22580512',\t'cg02288165', 'cg22549408','cg05740244','cg00019495']].to_csv('selected.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
