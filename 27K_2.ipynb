{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            age       histology\n",
       " id                             \n",
       " GSM491937  68.0    Endometrioid\n",
       " GSM491938  81.0  Carcinosarcoma\n",
       " GSM491939  56.0                \n",
       " GSM491940  62.0                \n",
       " GSM491941  72.0        Mucinous\n",
       " ...         ...             ...\n",
       " GSM492472  58.0                \n",
       " GSM492473  61.0                \n",
       " GSM492474  72.0                \n",
       " GSM492475  65.0                \n",
       " GSM492476  64.0                \n",
       " \n",
       " [540 rows x 2 columns],\n",
       "             GSM491937  GSM491938  GSM491939  GSM491940  GSM491941  GSM491942  \\\n",
       " id                                                                             \n",
       " cg00000292   0.756367   0.834702   0.774165   0.799517   0.819867   0.802813   \n",
       " cg00002426   0.797859   0.859538   0.769661   0.854328   0.853270   0.863897   \n",
       " cg00003994   0.068605   0.067469   0.056937   0.063802   0.061275   0.054674   \n",
       " cg00005847   0.131004   0.197486   0.140949   0.168209   0.137825   0.183501   \n",
       " cg00006414   0.076355   0.096817   0.156980   0.086761   0.079826   0.068110   \n",
       " ...               ...        ...        ...        ...        ...        ...   \n",
       " cg27657283   0.054350   0.060951   0.054692   0.051071   0.046700   0.058768   \n",
       " cg27661264   0.253198   0.427664   0.210370   0.241700   0.147942   0.335951   \n",
       " cg27662379   0.028654   0.022261   0.027410   0.025137   0.026827   0.027271   \n",
       " cg27662877   0.045494   0.044785   0.044007   0.032319   0.040882   0.041743   \n",
       " cg27665659   0.046754   0.051954   0.046282   0.043402   0.041331   0.040325   \n",
       " \n",
       "             GSM491943  GSM491944  GSM491945  GSM491946  ...  GSM492467  \\\n",
       " id                                                      ...              \n",
       " cg00000292   0.766562   0.822293   0.719792   0.804761  ...   0.807832   \n",
       " cg00002426   0.753301   0.800000   0.729566   0.849711  ...   0.864014   \n",
       " cg00003994   0.069777   0.068445   0.126118   0.067532  ...   0.054327   \n",
       " cg00005847   0.193419   0.136081   0.234453   0.165346  ...   0.150090   \n",
       " cg00006414   0.082719   0.080460   0.123699   0.099133  ...   0.088297   \n",
       " ...               ...        ...        ...        ...  ...        ...   \n",
       " cg27657283   0.088867   0.057243   0.157115   0.073481  ...   0.065930   \n",
       " cg27661264   0.278894   0.287979   0.292254   0.259373  ...   0.303476   \n",
       " cg27662379   0.022631   0.029155   0.027861   0.026356  ...   0.028295   \n",
       " cg27662877   0.045181   0.048036   0.068568   0.040477  ...   0.058025   \n",
       " cg27665659   0.046106   0.050578   0.045932        NaN  ...   0.045390   \n",
       " \n",
       "             GSM492468  GSM492469  GSM492470  GSM492471  GSM492472  GSM492473  \\\n",
       " id                                                                             \n",
       " cg00000292   0.755824   0.845683   0.832651   0.859874   0.850640   0.785949   \n",
       " cg00002426   0.832049   0.869352   0.852637   0.851757   0.811812   0.863659   \n",
       " cg00003994   0.062455   0.061526   0.053024   0.067747   0.046001   0.065620   \n",
       " cg00005847   0.200854   0.222263   0.145972   0.130132   0.165387   0.149490   \n",
       " cg00006414   0.087050   0.075793   0.076368   0.083054   0.074648   0.078410   \n",
       " ...               ...        ...        ...        ...        ...        ...   \n",
       " cg27657283   0.051468   0.044607   0.046881   0.047645   0.060186   0.044991   \n",
       " cg27661264   0.274077   0.364820   0.368968   0.379232   0.371981   0.433100   \n",
       " cg27662379   0.029780   0.030459   0.024485   0.018455   0.030636   0.034338   \n",
       " cg27662877   0.064934   0.047541   0.049245   0.039609   0.045670   0.033494   \n",
       " cg27665659   0.049339   0.044413   0.047632   0.047909   0.048369   0.037386   \n",
       " \n",
       "             GSM492474  GSM492475  GSM492476  \n",
       " id                                           \n",
       " cg00000292   0.827493   0.817919   0.555077  \n",
       " cg00002426   0.815332   0.860943   0.511268  \n",
       " cg00003994   0.055990   0.062512   0.210708  \n",
       " cg00005847   0.155754   0.129134   0.066549  \n",
       " cg00006414   0.091335   0.065681   0.056630  \n",
       " ...               ...        ...        ...  \n",
       " cg27657283   0.056461   0.047952   0.187679  \n",
       " cg27661264   0.422606   0.433005   0.499545  \n",
       " cg27662379   0.035688   0.034179   0.022769  \n",
       " cg27662877   0.035118   0.040766   0.092554  \n",
       " cg27665659   0.043518   0.048207   0.040923  \n",
       " \n",
       " [27578 rows x 540 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from biolearn.data_library import DataLibrary\n",
    "import pandas as pd\n",
    "# https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE19711\n",
    "\n",
    "data = DataLibrary().get(\"GSE19711\").load()\n",
    "data.metadata, data.dnam\n",
    "\n",
    "#elastic for selection, boost for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "X = data.dnam.transpose()\n",
    "X_df = pd.DataFrame(X)\n",
    "y = data.metadata['age']\n",
    "y = pd.DataFrame(y)\n",
    "cb = pd.merge(X_df, y, left_index=True, right_index=True)\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "cb = pd.DataFrame(imputer.fit_transform(cb), columns=cb.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id   cg00000292  cg00002426  cg00003994  cg00005847  cg00006414  cg00007981  \\\n",
       " 0      0.828262    0.854375    0.059711    0.115659    0.049387    0.027008   \n",
       " 1      0.734994    0.787240    0.052274    0.172818    0.075584    0.029014   \n",
       " 2      0.806843    0.863183    0.055113    0.087853    0.053807    0.019662   \n",
       " 3      0.784203    0.819974    0.079304    0.170066    0.072472    0.029986   \n",
       " 4      0.879105    0.810259    0.087841    0.178102    0.094256    0.062319   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 103    0.804033    0.823022    0.088943    0.197545    0.093083    0.035691   \n",
       " 104    0.789046    0.771894    0.142923    0.148564    0.127663    0.046614   \n",
       " 105    0.776728    0.788085    0.061667    0.135294    0.104459    0.039748   \n",
       " 106    0.696125    0.692183    0.113258    0.170320    0.065010    0.028731   \n",
       " 107    0.800268    0.849626    0.057081    0.143896    0.057264    0.027778   \n",
       " \n",
       " id   cg00008493  cg00008713  cg00009407  cg00010193  ...  cg27653134  \\\n",
       " 0      0.967979    0.031426    0.050074    0.608109  ...    0.785318   \n",
       " 1      0.942233    0.053090    0.079721    0.584574  ...    0.779333   \n",
       " 2      0.973710    0.025936    0.045661    0.652367  ...    0.836345   \n",
       " 3      0.948476    0.044676    0.074344    0.598542  ...    0.799035   \n",
       " 4      0.960331    0.026375    0.046886    0.818906  ...    0.794095   \n",
       " ..          ...         ...         ...         ...  ...         ...   \n",
       " 103    0.940250    0.043998    0.074566    0.586531  ...    0.756380   \n",
       " 104    0.962076    0.043432    0.050561    0.659893  ...    0.697060   \n",
       " 105    0.957468    0.033548    0.066967    0.563164  ...    0.798602   \n",
       " 106    0.956338    0.029787    0.070021    0.582571  ...    0.807649   \n",
       " 107    0.959398    0.041948    0.062239    0.618828  ...    0.776907   \n",
       " \n",
       " id   cg27654142  cg27655855  cg27655905  cg27657249  cg27657283  cg27661264  \\\n",
       " 0      0.064527    0.818422    0.063709    0.182329    0.053340    0.417254   \n",
       " 1      0.095233    0.797883    0.094889    0.187443    0.054979    0.306129   \n",
       " 2      0.063078    0.846769    0.061842    0.147310    0.031204    0.391967   \n",
       " 3      0.071913    0.832642    0.069783    0.190304    0.078955    0.357677   \n",
       " 4      0.065406    0.877368    0.043738    0.096728    0.053191    0.367893   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 103    0.095627    0.796206    0.087754    0.154297    0.066138    0.391582   \n",
       " 104    0.092292    0.777027    0.084047    0.153773    0.084205    0.294694   \n",
       " 105    0.041366    0.873287    0.077188    0.105887    0.059829    0.327007   \n",
       " 106    0.037481    0.848395    0.065506    0.094870    0.044063    0.316632   \n",
       " 107    0.050638    0.818388    0.075068    0.185181    0.046861    0.311433   \n",
       " \n",
       " id   cg27662379  cg27662877  cg27665659  \n",
       " 0      0.026760    0.032291    0.039678  \n",
       " 1      0.031369    0.065538    0.049112  \n",
       " 2      0.024236    0.030789    0.031996  \n",
       " 3      0.027167    0.034625    0.038829  \n",
       " 4      0.030189    0.051091    0.031154  \n",
       " ..          ...         ...         ...  \n",
       " 103    0.032076    0.059015    0.054599  \n",
       " 104    0.053894    0.055599    0.052798  \n",
       " 105    0.038400    0.043623    0.039833  \n",
       " 106    0.027728    0.041888    0.030979  \n",
       " 107    0.022377    0.037542    0.043276  \n",
       " \n",
       " [108 rows x 27578 columns],\n",
       "             age\n",
       " id             \n",
       " GSM492166  73.0\n",
       " GSM492010  58.0\n",
       " GSM492458  58.0\n",
       " GSM492023  73.0\n",
       " GSM492406  70.0\n",
       " ...         ...\n",
       " GSM492435  77.0\n",
       " GSM492085  53.0\n",
       " GSM491983  59.0\n",
       " GSM492030  60.0\n",
       " GSM492343  71.0\n",
       " \n",
       " [108 rows x 1 columns])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_df, y, test_size=0.2, random_state=42)\n",
    "X_test2 = pd.DataFrame(imputer.fit_transform(X_test2), columns=X_test2.columns)\n",
    "X_test2, y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfe for feature selection\n",
    "\n",
    "\n",
    "X_imputed = cb.drop(columns=['age'])\n",
    "y_imputed = cb['age']\n",
    "\n",
    "# Feature selection using RFE with SVM\n",
    "svr = SVR(kernel='linear')\n",
    "rfe = RFE(estimator=svr, n_features_to_select=200, step=25)\n",
    "rfe.fit(X_imputed, y_imputed)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_imputed.columns[rfe.support_]\n",
    "\n",
    "# Select the top 200 features\n",
    "X_selected = X_imputed[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.03435020157261, 2.8406084484078655, 0.7696680969303518)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_imputed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an SVM model\n",
    "svm_model = SVR(kernel='linear',C=10, epsilon=1.8)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petra/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.03435020157261, 2.8406084484078655, 0.7696680969303518)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an SVM model\n",
    "svm_model = SVR(kernel='linear',C=10, epsilon=1.8)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    'sampleId': y_test.index,\n",
    "    'predictedAge': y_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sampleId  predictedAge\n",
      "0       229     72.009625\n",
      "1        73     59.335954\n",
      "2       521     57.433693\n",
      "3        86     62.354625\n",
      "4       469     72.825691\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    'sampleId': X_test.index,\n",
    "    'predictedAge': y_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv('predictions.csv', index=False)\n",
    "\n",
    "# Output for sanity check\n",
    "print(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Assuming X_genomic is your genomic dataset and y_age is the corresponding age labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the ElasticNetCV model\n",
    "alpha_values = np.logspace(-3, 3, 10)  # Range of alpha values to search\n",
    "l1_ratio_values = [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]  # Range of l1_ratio values to search\n",
    "elasticnet_cv = ElasticNetCV(alphas=alpha_values, l1_ratio=l1_ratio_values, cv=5)\n",
    "elasticnet_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the selected alpha and l1_ratio values\n",
    "print(\"Selected alpha:\", elasticnet_cv.alpha_)\n",
    "print(\"Selected l1_ratio:\", elasticnet_cv.l1_ratio_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_score = elasticnet_cv.score(X_test, y_test)\n",
    "print(\"Test Set R^2 Score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  feature selection\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "X_feat = X\n",
    "y_feat = y\n",
    "# X_feat, y = make_regression(n_samples=100, n_features=100, noise=0.1, random_state=42)\n",
    "model = ElasticNet(alpha=0.00464, l1_ratio=0.1) \n",
    "model.fit(X_feat, y_feat)\n",
    "feature_importance = model.coef_\n",
    "sorted_indices = np.argsort(np.abs(feature_importance))[::-1]\n",
    "top_features = sorted_indices[:10]\n",
    "# print(\"Top features:\")\n",
    "# for idx in top_features:\n",
    "#     print(f\"Feature {idx}: {feature_importance[idx]}\")\n",
    "top_feature_names = X_feat.columns[top_features]\n",
    "top_feature_coefficients = feature_importance[top_features]\n",
    "\n",
    "# Create a DataFrame with feature names and their coefficients\n",
    "feature_data = pd.DataFrame({\n",
    "    'Feature': top_feature_names,\n",
    "    'Coefficient': top_feature_coefficients\n",
    "})\n",
    "\n",
    "print(\"Top features and their coefficients:\")\n",
    "print(feature_data)\n",
    "\n",
    "# Output to CSV\n",
    "feature_data.to_csv('top_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose = cb[['age', 'cg06493994','cg22736354', 'cg18219226', 'cg02228185',\t'cg22580512',\t'cg02288165']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds_df = pd.DataFrame({'sampleId': X_df.index, 'predictedAge': y_pred})\n",
    "preds_df.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### XGBoost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "#X_choose, y = make_regression(n_samples=100, n_features=100, noise=0.1, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(choose.drop('age', axis=1), choose['age'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=150, learning_rate=0.15, max_depth=2, reg_alpha=1, reg_lambda=0.1)\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric='rmse', early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = xgb_model.score(X_train, y_train)\n",
    "test_score = xgb_model.score(X_test, y_test)\n",
    "print(\"XGBoost model train score:\", train_score)\n",
    "print(\"XGBoost model test score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predictions on the training and testing sets\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE on training set:\", mse_train)\n",
    "print(\"MSE on testing set:\", mse_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "\n",
    "# Calculate R-squared (R2) score\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(\"R-squared (R2) score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],      # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Instantiate the Random Forest regressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_train_pred = best_rf_model.predict(X_train)\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE on training set with best model:\", mse_train)\n",
    "print(\"MSE on testing set with best model:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Instantiate a new Random Forest model with the best parameters\n",
    "best_rf_model = RandomForestRegressor(n_estimators=150,\n",
    "                                       #max_depth=5,\n",
    "                                       min_samples_split=2,\n",
    "                                       min_samples_leaf=4,\n",
    "                                       random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE on testing set with best model:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb[['age', 'cg06493994','cg22736354', 'cg18219226', 'cg02228185',\t'cg22580512',\t'cg02288165', 'cg22549408','cg05740244','cg00019495']].to_csv('selected.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
