{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biolearn.data_library import DataLibrary\n",
    "import pandas as pd\n",
    "# https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE19711\n",
    "\n",
    "data = DataLibrary().get(\"GSE19711\").load()\n",
    "data.metadata, data.dnam\n",
    "\n",
    "#elastic for selection, boost for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00000292</th>\n",
       "      <th>cg00002426</th>\n",
       "      <th>cg00003994</th>\n",
       "      <th>cg00005847</th>\n",
       "      <th>cg00006414</th>\n",
       "      <th>cg00007981</th>\n",
       "      <th>cg00008493</th>\n",
       "      <th>cg00008713</th>\n",
       "      <th>cg00009407</th>\n",
       "      <th>cg00010193</th>\n",
       "      <th>...</th>\n",
       "      <th>cg27654142</th>\n",
       "      <th>cg27655855</th>\n",
       "      <th>cg27655905</th>\n",
       "      <th>cg27657249</th>\n",
       "      <th>cg27657283</th>\n",
       "      <th>cg27661264</th>\n",
       "      <th>cg27662379</th>\n",
       "      <th>cg27662877</th>\n",
       "      <th>cg27665659</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM491937</th>\n",
       "      <td>0.756367</td>\n",
       "      <td>0.797859</td>\n",
       "      <td>0.068605</td>\n",
       "      <td>0.131004</td>\n",
       "      <td>0.076355</td>\n",
       "      <td>0.031687</td>\n",
       "      <td>0.946473</td>\n",
       "      <td>0.030616</td>\n",
       "      <td>0.073854</td>\n",
       "      <td>0.594014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044225</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>0.088685</td>\n",
       "      <td>0.161284</td>\n",
       "      <td>0.054350</td>\n",
       "      <td>0.253198</td>\n",
       "      <td>0.028654</td>\n",
       "      <td>0.045494</td>\n",
       "      <td>0.046754</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM491938</th>\n",
       "      <td>0.834702</td>\n",
       "      <td>0.859538</td>\n",
       "      <td>0.067469</td>\n",
       "      <td>0.197486</td>\n",
       "      <td>0.096817</td>\n",
       "      <td>0.027651</td>\n",
       "      <td>0.956317</td>\n",
       "      <td>0.036103</td>\n",
       "      <td>0.080879</td>\n",
       "      <td>0.568817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193395</td>\n",
       "      <td>0.851130</td>\n",
       "      <td>0.074006</td>\n",
       "      <td>0.236641</td>\n",
       "      <td>0.060951</td>\n",
       "      <td>0.427664</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.044785</td>\n",
       "      <td>0.051954</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM491939</th>\n",
       "      <td>0.774165</td>\n",
       "      <td>0.769661</td>\n",
       "      <td>0.056937</td>\n",
       "      <td>0.140949</td>\n",
       "      <td>0.156980</td>\n",
       "      <td>0.027933</td>\n",
       "      <td>0.952377</td>\n",
       "      <td>0.038230</td>\n",
       "      <td>0.064909</td>\n",
       "      <td>0.575405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075082</td>\n",
       "      <td>0.822084</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.187616</td>\n",
       "      <td>0.054692</td>\n",
       "      <td>0.210370</td>\n",
       "      <td>0.027410</td>\n",
       "      <td>0.044007</td>\n",
       "      <td>0.046282</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM491940</th>\n",
       "      <td>0.799517</td>\n",
       "      <td>0.854328</td>\n",
       "      <td>0.063802</td>\n",
       "      <td>0.168209</td>\n",
       "      <td>0.086761</td>\n",
       "      <td>0.029277</td>\n",
       "      <td>0.961985</td>\n",
       "      <td>0.037684</td>\n",
       "      <td>0.065395</td>\n",
       "      <td>0.588644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073761</td>\n",
       "      <td>0.816040</td>\n",
       "      <td>0.076892</td>\n",
       "      <td>0.167379</td>\n",
       "      <td>0.051071</td>\n",
       "      <td>0.241700</td>\n",
       "      <td>0.025137</td>\n",
       "      <td>0.032319</td>\n",
       "      <td>0.043402</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM491941</th>\n",
       "      <td>0.819867</td>\n",
       "      <td>0.853270</td>\n",
       "      <td>0.061275</td>\n",
       "      <td>0.137825</td>\n",
       "      <td>0.079826</td>\n",
       "      <td>0.037950</td>\n",
       "      <td>0.960325</td>\n",
       "      <td>0.034399</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.582535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070806</td>\n",
       "      <td>0.436428</td>\n",
       "      <td>0.081855</td>\n",
       "      <td>0.163969</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.147942</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.040882</td>\n",
       "      <td>0.041331</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM492472</th>\n",
       "      <td>0.850640</td>\n",
       "      <td>0.811812</td>\n",
       "      <td>0.046001</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.074648</td>\n",
       "      <td>0.031145</td>\n",
       "      <td>0.952253</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>0.093094</td>\n",
       "      <td>0.636976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.830900</td>\n",
       "      <td>0.090231</td>\n",
       "      <td>0.142626</td>\n",
       "      <td>0.060186</td>\n",
       "      <td>0.371981</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.045670</td>\n",
       "      <td>0.048369</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM492473</th>\n",
       "      <td>0.785949</td>\n",
       "      <td>0.863659</td>\n",
       "      <td>0.065620</td>\n",
       "      <td>0.149490</td>\n",
       "      <td>0.078410</td>\n",
       "      <td>0.028611</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.035945</td>\n",
       "      <td>0.081228</td>\n",
       "      <td>0.607439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059076</td>\n",
       "      <td>0.827640</td>\n",
       "      <td>0.080969</td>\n",
       "      <td>0.172553</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>0.433100</td>\n",
       "      <td>0.034338</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.037386</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM492474</th>\n",
       "      <td>0.827493</td>\n",
       "      <td>0.815332</td>\n",
       "      <td>0.055990</td>\n",
       "      <td>0.155754</td>\n",
       "      <td>0.091335</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.954158</td>\n",
       "      <td>0.040996</td>\n",
       "      <td>0.084361</td>\n",
       "      <td>0.607488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086786</td>\n",
       "      <td>0.828041</td>\n",
       "      <td>0.092011</td>\n",
       "      <td>0.162151</td>\n",
       "      <td>0.056461</td>\n",
       "      <td>0.422606</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.035118</td>\n",
       "      <td>0.043518</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM492475</th>\n",
       "      <td>0.817919</td>\n",
       "      <td>0.860943</td>\n",
       "      <td>0.062512</td>\n",
       "      <td>0.129134</td>\n",
       "      <td>0.065681</td>\n",
       "      <td>0.025430</td>\n",
       "      <td>0.966155</td>\n",
       "      <td>0.045333</td>\n",
       "      <td>0.075592</td>\n",
       "      <td>0.611718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.839257</td>\n",
       "      <td>0.098245</td>\n",
       "      <td>0.169964</td>\n",
       "      <td>0.047952</td>\n",
       "      <td>0.433005</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>0.040766</td>\n",
       "      <td>0.048207</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM492476</th>\n",
       "      <td>0.555077</td>\n",
       "      <td>0.511268</td>\n",
       "      <td>0.210708</td>\n",
       "      <td>0.066549</td>\n",
       "      <td>0.056630</td>\n",
       "      <td>0.176972</td>\n",
       "      <td>0.931410</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.047197</td>\n",
       "      <td>0.636726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094438</td>\n",
       "      <td>0.805744</td>\n",
       "      <td>0.147458</td>\n",
       "      <td>0.201412</td>\n",
       "      <td>0.187679</td>\n",
       "      <td>0.499545</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>0.092554</td>\n",
       "      <td>0.040923</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 27579 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cg00000292  cg00002426  cg00003994  cg00005847  cg00006414  \\\n",
       "GSM491937    0.756367    0.797859    0.068605    0.131004    0.076355   \n",
       "GSM491938    0.834702    0.859538    0.067469    0.197486    0.096817   \n",
       "GSM491939    0.774165    0.769661    0.056937    0.140949    0.156980   \n",
       "GSM491940    0.799517    0.854328    0.063802    0.168209    0.086761   \n",
       "GSM491941    0.819867    0.853270    0.061275    0.137825    0.079826   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "GSM492472    0.850640    0.811812    0.046001    0.165387    0.074648   \n",
       "GSM492473    0.785949    0.863659    0.065620    0.149490    0.078410   \n",
       "GSM492474    0.827493    0.815332    0.055990    0.155754    0.091335   \n",
       "GSM492475    0.817919    0.860943    0.062512    0.129134    0.065681   \n",
       "GSM492476    0.555077    0.511268    0.210708    0.066549    0.056630   \n",
       "\n",
       "           cg00007981  cg00008493  cg00008713  cg00009407  cg00010193  ...  \\\n",
       "GSM491937    0.031687    0.946473    0.030616    0.073854    0.594014  ...   \n",
       "GSM491938    0.027651    0.956317    0.036103    0.080879    0.568817  ...   \n",
       "GSM491939    0.027933    0.952377    0.038230    0.064909    0.575405  ...   \n",
       "GSM491940    0.029277    0.961985    0.037684    0.065395    0.588644  ...   \n",
       "GSM491941    0.037950    0.960325    0.034399    0.076923    0.582535  ...   \n",
       "...               ...         ...         ...         ...         ...  ...   \n",
       "GSM492472    0.031145    0.952253    0.036039    0.093094    0.636976  ...   \n",
       "GSM492473    0.028611    0.958846    0.035945    0.081228    0.607439  ...   \n",
       "GSM492474    0.042109    0.954158    0.040996    0.084361    0.607488  ...   \n",
       "GSM492475    0.025430    0.966155    0.045333    0.075592    0.611718  ...   \n",
       "GSM492476    0.176972    0.931410    0.015440    0.047197    0.636726  ...   \n",
       "\n",
       "           cg27654142  cg27655855  cg27655905  cg27657249  cg27657283  \\\n",
       "GSM491937    0.044225    0.818353    0.088685    0.161284    0.054350   \n",
       "GSM491938    0.193395    0.851130    0.074006    0.236641    0.060951   \n",
       "GSM491939    0.075082    0.822084    0.073700    0.187616    0.054692   \n",
       "GSM491940    0.073761    0.816040    0.076892    0.167379    0.051071   \n",
       "GSM491941    0.070806    0.436428    0.081855    0.163969    0.046700   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "GSM492472    0.066265    0.830900    0.090231    0.142626    0.060186   \n",
       "GSM492473    0.059076    0.827640    0.080969    0.172553    0.044991   \n",
       "GSM492474    0.086786    0.828041    0.092011    0.162151    0.056461   \n",
       "GSM492475    0.090769    0.839257    0.098245    0.169964    0.047952   \n",
       "GSM492476    0.094438    0.805744    0.147458    0.201412    0.187679   \n",
       "\n",
       "           cg27661264  cg27662379  cg27662877  cg27665659   age  \n",
       "GSM491937    0.253198    0.028654    0.045494    0.046754  68.0  \n",
       "GSM491938    0.427664    0.022261    0.044785    0.051954  81.0  \n",
       "GSM491939    0.210370    0.027410    0.044007    0.046282  56.0  \n",
       "GSM491940    0.241700    0.025137    0.032319    0.043402  62.0  \n",
       "GSM491941    0.147942    0.026827    0.040882    0.041331  72.0  \n",
       "...               ...         ...         ...         ...   ...  \n",
       "GSM492472    0.371981    0.030636    0.045670    0.048369  58.0  \n",
       "GSM492473    0.433100    0.034338    0.033494    0.037386  61.0  \n",
       "GSM492474    0.422606    0.035688    0.035118    0.043518  72.0  \n",
       "GSM492475    0.433005    0.034179    0.040766    0.048207  65.0  \n",
       "GSM492476    0.499545    0.022769    0.092554    0.040923  64.0  \n",
       "\n",
       "[540 rows x 27579 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = data.dnam.transpose()\n",
    "X_df = pd.DataFrame(X)\n",
    "y = data.metadata['age']\n",
    "y = pd.DataFrame(y)\n",
    "cb = pd.merge(X_df, y, left_index=True, right_index=True)\n",
    "cb_imputed = SimpleImputer(strategy='mean').fit_transform(cb)\n",
    "cb = pd.DataFrame(cb_imputed, columns=cb.columns, index=cb.index)\n",
    "\n",
    "X = cb.drop('age', axis=1)\n",
    "y = cb['age']\n",
    "\n",
    "cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.152e+00, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+02, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e+02, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.028e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.551e+02, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.269e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.603e+00, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+02, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.279e+02, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.601e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.193e+00, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+02, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+02, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e+01, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.608e+02, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+02, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.090e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.681e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+02, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.865e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.647e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.136e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.103e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+02, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.294e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.902e+01, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+02, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+01, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.180e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.247e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.856e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.583e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.444e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.592e+00, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.276e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.578e+01, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+01, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.098e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.588e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.699e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.882e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+01, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.904e+01, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.770e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.775e+00, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+01, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.960e+00, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.705e+01, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.759e+01, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.849e+00, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+01, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.264e+00, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e+00, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.862e+01, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.513e+00, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.049e+00, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.317e+00, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.286e+01, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.809e+00, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.030e+00, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.986e+00, tolerance: 2.345e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.936e+00, tolerance: 2.312e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.249e+00, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.546e+00, tolerance: 2.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.489e+00, tolerance: 2.392e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.495e+00, tolerance: 2.366e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected alpha: 0.004641588833612777\n",
      "Selected l1_ratio: 0.1\n",
      "Test Set R^2 Score: 0.3855392821019268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.207e+02, tolerance: 2.881e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Assuming X_genomic is your genomic dataset and y_age is the corresponding age labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the ElasticNetCV model\n",
    "alpha_values = np.logspace(-3, 3, 10)  # Range of alpha values to search\n",
    "l1_ratio_values = [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]  # Range of l1_ratio values to search\n",
    "elasticnet_cv = ElasticNetCV(alphas=alpha_values, l1_ratio=l1_ratio_values, cv=5)\n",
    "elasticnet_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the selected alpha and l1_ratio values\n",
    "print(\"Selected alpha:\", elasticnet_cv.alpha_)\n",
    "print(\"Selected l1_ratio:\", elasticnet_cv.l1_ratio_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_score = elasticnet_cv.score(X_test, y_test)\n",
    "print(\"Test Set R^2 Score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features and their coefficients:\n",
      "       Feature  Coefficient\n",
      "0   cg02228185    -2.801396\n",
      "1   cg22580512    -2.403753\n",
      "2   cg02288165     2.280634\n",
      "3   cg22549408     2.252155\n",
      "4   cg05740244    -2.014717\n",
      "..         ...          ...\n",
      "95  cg16986846     1.073531\n",
      "96  cg15364618    -1.072202\n",
      "97  cg02082342    -1.071462\n",
      "98  cg08888956    -1.070986\n",
      "99  cg20812929    -1.066942\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.981e+02, tolerance: 3.586e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#####  feature selection\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "X_feat = X\n",
    "y_feat = y\n",
    "# X_feat, y = make_regression(n_samples=100, n_features=100, noise=0.1, random_state=42)\n",
    "model = ElasticNet(alpha=0.00464, l1_ratio=0.1) \n",
    "model.fit(X_feat, y_feat)\n",
    "feature_importance = model.coef_\n",
    "sorted_indices = np.argsort(np.abs(feature_importance))[::-1]\n",
    "top_features = sorted_indices[:100]\n",
    "# print(\"Top features:\")\n",
    "# for idx in top_features:\n",
    "#     print(f\"Feature {idx}: {feature_importance[idx]}\")\n",
    "top_feature_names = X_feat.columns[top_features]\n",
    "top_feature_coefficients = feature_importance[top_features]\n",
    "\n",
    "# Create a DataFrame with feature names and their coefficients\n",
    "feature_data = pd.DataFrame({\n",
    "    'Feature': top_feature_names,\n",
    "    'Coefficient': top_feature_coefficients\n",
    "})\n",
    "\n",
    "print(\"Top features and their coefficients:\")\n",
    "print(feature_data)\n",
    "\n",
    "# Output to CSV\n",
    "feature_data.to_csv('top_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose = cb[['age', 'cg02228185',\t'cg22580512',\t'cg02288165',\t'cg22549408',\t'cg05740244',\t'cg00019495',\t'cg23762517',\t'cg10935723',\t'cg07327347',\t'cg18771300',\t'cg07884019',\t'cg10523019',\t'cg25133685',\t'cg06590711',\t'cg00141845',\t'cg02654291',\t'cg07388493',\t'cg07403350',\t'cg24429836',\t'cg23124451',\t'cg25004981',\t'cg03454353',\t'cg14088161',\t'cg14826456',\t'cg22736354',\t'cg16474696',\t'cg09835085',\t'cg01512854',\t'cg12650635',\t'cg17901463',\t'cg11126134',\t'cg17471102',\t'cg03923277',\t'cg26987645',\t'cg06771126',\t'cg22333868',\t'cg07693270',\t'cg04019407',\t'cg13460409',\t'cg10203483',\t'cg20797216',\t'cg25681177',\t'cg16685388',\t'cg19258882',\t'cg22983460',\t'cg20916523',\t'cg01136458',\t'cg13269407',\t'cg17073891',\t'cg13301003',\t'cg14951292',\t'cg20945531',\t'cg04230060',\t'cg16005224',\t'cg13944141',\t'cg22901840',\t'cg13899108',\t'cg13119609',\t'cg16440909',\t'cg06906435',\t'cg17655614',\t'cg05254747',\t'cg19856594',\t'cg03330058',\t'cg04123409',\t'cg04037228',\t'cg03764585',\t'cg23504246',\t'cg13749822',\t'cg01693350',\t'cg07905963',\t'cg23894058',\t'cg21053323',\t'cg16744741',\t'cg23771661',\t'cg06791102',\t'cg23180489',\t'cg21120249',\t'cg11108890',\t'cg16742703',\t'cg00451635',\t'cg04384208',\t'cg13033054',\t'cg01837574',\t'cg25809905',\t'cg19421044',\t'cg25345738',\t'cg25569462',\t'cg20977864',\t'cg04300115',\t'cg06143901',\t'cg09554443',\t'cg17704839',\t'cg10978346',\t'cg12215675',\t'cg16986846',\t'cg15364618',\t'cg02082342',\t'cg08888956',\t'cg20812929']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model train score: 0.866776941054914\n",
      "XGBoost model test score: 0.4983150409058519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###### XGBoost\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "#X_choose, y = make_regression(n_samples=100, n_features=100, noise=0.1, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(choose.drop('age', axis=1), choose['age'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.5, max_depth=2, reg_alpha=1.05, reg_lambda=0.1)\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric='rmse', early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = xgb_model.score(X_train, y_train)\n",
    "test_score = xgb_model.score(X_test, y_test)\n",
    "print(\"XGBoost model train score:\", train_score)\n",
    "print(\"XGBoost model test score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on training set: 8.883535351900989\n",
      "MSE on testing set: 32.74625557885628\n",
      "R-squared (R2) score: 0.4983150409058519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predictions on the training and testing sets\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE on training set:\", mse_train)\n",
    "print(\"MSE on testing set:\", mse_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "\n",
    "# Calculate R-squared (R2) score\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(\"R-squared (R2) score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "MSE on training set with best model: 7.270987812522735\n",
      "MSE on testing set with best model: 37.20199270473101\n"
     ]
    }
   ],
   "source": [
    "#########random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],      # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Instantiate the Random Forest regressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_train_pred = best_rf_model.predict(X_train)\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE on training set with best model:\", mse_train)\n",
    "print(\"MSE on testing set with best model:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on testing set with best model: 37.20199270473101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Instantiate a new Random Forest model with the best parameters\n",
    "best_rf_model = RandomForestRegressor(n_estimators=150,\n",
    "                                       #max_depth=5,\n",
    "                                       min_samples_split=2,\n",
    "                                       min_samples_leaf=2,\n",
    "                                       random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE on testing set with best model:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'epsilon': 0.5, 'kernel': 'linear'}\n",
      "R-squared on training set with best model: 0.6957196926436576\n",
      "R-squared on testing set with best model: 0.4110868770709625\n",
      "MAE on training set with best model: 3.2878876823905845\n",
      "MAE on testing set with best model: 4.64367091547614\n",
      "MSE on training set with best model: 20.289917441406033\n",
      "MSE on testing set with best model: 38.4398600906782\n"
     ]
    }
   ],
   "source": [
    "####### SVM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Instantiate the SVM regressor with the desired hyperparameters\n",
    "svm_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "# Fit the SVM model to the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'epsilon': [0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model\n",
    "y_train_pred = best_svm_model.predict(X_train)\n",
    "y_test_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"R-squared on training set with best model:\", train_r2)\n",
    "print(\"R-squared on testing set with best model:\", test_r2)\n",
    "print(\"MAE on training set with best model:\", train_mae)\n",
    "print(\"MAE on testing set with best model:\", test_mae)\n",
    "print(\"MSE on training set with best model:\", train_mse)\n",
    "print(\"MSE on testing set with best model:\", test_mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
